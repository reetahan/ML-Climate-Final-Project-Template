{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import pandas as pd\n",
    "from flaml import AutoML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "from sklearn.manifold import LocallyLinearEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e332d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data():\n",
    "    #Open the datasets\n",
    "    factual = xr.open_mfdataset(\"factual/*.nc\")\n",
    "    cfl = xr.open_mfdataset(\"eth_cfl/*.nc\", join='inner', compat='override')\n",
    "    \n",
    "    factual = factual.reduce(np.nansum, dim='expver',keep_attrs=True)\n",
    "    cfl[\"lon\"] = np.arange(-180,180,2.5)\n",
    "    factual = factual.rename({\"latitude\":\"lat\",\"longitude\":\"lon\"})\n",
    "    cfl = cfl.sel(lat=slice(-60,60),lon=slice(-80,20))\n",
    "    \n",
    "    #Regrid the factual dataset to be the counterfactual's granularity\n",
    "    ds_out = xr.Dataset(\n",
    "        {\n",
    "            \"lat\": np.array(cfl[\"lat\"]),\n",
    "            \"lon\": np.array(cfl[\"lon\"]),\n",
    "        }\n",
    "    )\n",
    "    regridder = xe.Regridder(factual, ds_out, \"bilinear\")\n",
    "    factual = regridder(factual)\n",
    "    #factual = factual.isel(time=slice(0,864)) \n",
    "    factual = factual.isel(time=slice(0,732)) # if monthly data\n",
    "    \n",
    "    pred_df = pd.read_csv(\"yearly_activity.csv\")\n",
    "    pred_df = pred_df.loc[pred_df['Year'] >= 1950]\n",
    "    ace_raw = pred_df['Accumulated Cyclone Energy']\n",
    "    ace = np.array(ace_raw)\n",
    "    \n",
    "    return factual,cfl,ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9d9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual, cfl, ace = open_data()\n",
    "factual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b97d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual = factual.to_array().transpose(\"time\",\"variable\",\"lat\",\"lon\")\n",
    "factual = factual.resample(time='AS').mean()\n",
    "factual = factual.stack(location=['lat','lon'])\n",
    "factual = factual.mean(dim=[\"location\"])\n",
    "factual = factual.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773b189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(factual,ace,test_size=0.3,shuffle=True, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a09e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "        \"metric\": 'rmse',\n",
    "        \"estimator_list\": 'auto',\n",
    "        \"task\": 'regression',\n",
    "        \"time_budget\": 300,\n",
    "        \"log_file_name\": \"./automl_factual.log\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d1222",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.fit(X_train=X_train, y_train=y_train,**automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_results(y_test,y_pred):\n",
    "    print('R^2 Score: ' + str(r2_score(y_test, y_pred)))\n",
    "    print('LGBM - RMSE: ' + str(mean_squared_error(y_test,y_pred, squared = False)))\n",
    "    print('LGBM - MAE: ' + str(mean_absolute_error(y_test,y_pred)))\n",
    "    plt.scatter(np.arange(len(y_test)), y_test,label='Observed')\n",
    "    plt.scatter(np.arange(len(y_test)), y_pred,label='Predicted')\n",
    "    plt.xlabel('Predicted Season')\n",
    "    plt.ylabel('Predicted ACE'),\n",
    "    plt.title('Testing Results')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.scatter(y_test,y_pred)\n",
    "    plt.xlabel('Observed')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title('Testing Results - Predicted v Observed')\n",
    "    plt.show()\n",
    "    plt.scatter(y_test, y_test-y_pred)\n",
    "    plt.plot(y_test,np.zeros(len(y_test)))\n",
    "    plt.xlabel('Observed')\n",
    "    plt.ylabel('Residual from Predicted')\n",
    "    plt.title('Testing Results - Residual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55436624",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual, cfl, ace = open_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5beabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual = factual.to_array().transpose(\"time\",\"variable\",\"lat\",\"lon\")\n",
    "factual = factual.resample(time='AS').mean()\n",
    "factual = factual.stack(information=['lat','lon','variable'])\n",
    "factual = factual.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da337c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(factual,ace,test_size=0.3,shuffle=True, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "        \"metric\": 'rmse',\n",
    "        \"estimator_list\": 'auto',\n",
    "        \"task\": 'regression',\n",
    "        \"time_budget\": 300,\n",
    "        \"log_file_name\": \"./automl_factual.log\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae86f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.fit(X_train=X_train, y_train=y_train,**automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fa3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual, cfl, ace = open_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d571a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual = factual.to_array().transpose(\"time\",\"variable\",\"lat\",\"lon\")\n",
    "factual = factual.resample(time='AS').mean()\n",
    "factual = factual.stack(information=['lat','lon','variable'])\n",
    "factual = factual.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d14dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual = StandardScaler().fit_transform(factual)\n",
    "factual = factual.T\n",
    "print(np.shape(factual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f63ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=63)\n",
    "pca.fit_transform(factual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f2d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual = pca.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(factual,ace,test_size=0.3,shuffle=True, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eff4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "        \"metric\": 'rmse',\n",
    "        \"estimator_list\": 'auto',\n",
    "        \"task\": 'regression',\n",
    "        \"time_budget\": 300,\n",
    "        \"log_file_name\": \"./automl_factual.log\"\n",
    "    }\n",
    "automl.fit(X_train=X_train, y_train=y_train,**automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa6c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09238716",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual, cfl, ace = open_data()\n",
    "factual = factual.to_array().transpose(\"time\",\"variable\",\"lat\",\"lon\")\n",
    "factual = factual.resample(time='AS').mean()\n",
    "factual = factual.stack(information=['lat','lon','variable'])\n",
    "factual = factual.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e560c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual = StandardScaler().fit_transform(factual)\n",
    "print(np.shape(factual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87401d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lle = LocallyLinearEmbedding(n_components=62)\n",
    "lle.fit(factual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual = lle.embedding_\n",
    "print(np.shape(factual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0353b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(factual,ace,test_size=0.3,shuffle=True, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "        \"metric\": 'rmse',\n",
    "        \"estimator_list\": 'auto',\n",
    "        \"task\": 'regression',\n",
    "        \"time_budget\": 300,\n",
    "        \"log_file_name\": \"./automl_factual.log\"\n",
    "    }\n",
    "automl.fit(X_train=X_train, y_train=y_train,**automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e4f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823afbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def water_open_data():\n",
    "    #Open the datasets\n",
    "    factual = xr.open_mfdataset(\"factual/*.nc\")\n",
    "    cfl = xr.open_mfdataset(\"eth_cfl/*.nc\", join='inner', compat='override')\n",
    "    \n",
    "    land_mask = xr.open_dataset(\"land_mask_gen.nc\")\n",
    "    \n",
    "    factual = factual.reduce(np.nansum, dim='expver',keep_attrs=True)\n",
    "    cfl[\"lon\"] = np.arange(-180,180,2.5)\n",
    "    factual = factual.rename({\"latitude\":\"lat\",\"longitude\":\"lon\"})\n",
    "    land_mask = land_mask.rename({\"latitude\":\"lat\",\"longitude\":\"lon\"})\n",
    "    \n",
    "    ds_out_land = xr.Dataset(\n",
    "        {\n",
    "            \"lat\": np.array(cfl[\"lat\"]),\n",
    "            \"lon\": np.array(cfl[\"lon\"]),\n",
    "        }\n",
    "    )\n",
    "    regridder_mask = xe.Regridder(land_mask, ds_out_land, \"bilinear\",reuse_weights=True)\n",
    "    land_mask = regridder_mask(land_mask)\n",
    "    \n",
    "    cfl = cfl.sel(lat=slice(-60,60),lon=slice(-80,20))\n",
    "    land_mask = land_mask.sel(lat=slice(-60,60),lon=slice(-80,20))\n",
    "    \n",
    "    #Regrid the factual dataset to be the counterfactual's granularity\n",
    "    ds_out = xr.Dataset(\n",
    "        {\n",
    "            \"lat\": np.array(cfl[\"lat\"]),\n",
    "            \"lon\": np.array(cfl[\"lon\"]),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    ds_out_land = xr.Dataset(\n",
    "        {\n",
    "            \"lat\": np.array(cfl[\"lat\"]),\n",
    "            \"lon\": np.array(cfl[\"lon\"]),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    regridder = xe.Regridder(factual, ds_out, \"bilinear\",reuse_weights=True)\n",
    "    factual = regridder(factual)\n",
    "    #factual = factual.isel(time=slice(0,756))\n",
    "    factual = factual.isel(time=slice(0,732)) #monthly data\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    pred_df = pd.read_csv(\"yearly_activity.csv\")\n",
    "    pred_df = pred_df.loc[pred_df['Year'] >= 1959]\n",
    "    ace_raw = pred_df['Accumulated Cyclone Energy']\n",
    "    ace = np.array(ace_raw)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return factual,cfl,ace, land_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a568239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual,cfl,ace, land_mask = water_open_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4848082",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual = factual.to_array().transpose(\"time\",\"lat\",\"lon\",\"variable\")\n",
    "#factual = factual.resample(time='AS').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask = land_mask.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caee5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#land_mask = np.repeat(land_mask[:, :, np.newaxis], 5, axis=2)\n",
    "#land_mask = np.repeat(land_mask[:, :, :, np.newaxis], 63, axis=3)\n",
    "land_mask = np.dstack([land_mask]*5)\n",
    "land_mask = np.dstack([land_mask]*756)\n",
    "land_mask = land_mask.reshape((756,64,41,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416456b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask = np.where(land_mask < 0.5, np.NaN, 1)\n",
    "factual = np.multiply(factual,land_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e16836",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual = factual.resample(time='AS').mean()\n",
    "factual = factual.stack(information=['lat','lon','variable'])\n",
    "factual = factual.to_numpy()\n",
    "factual = factual[:, ~np.isnan(factual).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f2cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(factual,ace,test_size=0.3,shuffle=True, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1949d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "        \"metric\": 'rmse',\n",
    "        \"estimator_list\": 'auto',\n",
    "        \"task\": 'regression',\n",
    "        \"time_budget\": 300,\n",
    "        \"log_file_name\": \"./automl_factual.log\"\n",
    "    }\n",
    "automl.fit(X_train=X_train, y_train=y_train,**automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4fb05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "eval_results(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a722dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_monthly_data():\n",
    "    mace = open(\"monthly_activity_ace.csv\",\"r\")\n",
    "    mns = open(\"monthly_activity_num_storms.csv\",\"r\")\n",
    "    \n",
    "    mace_contents = mace.readlines()\n",
    "    mns_contents = mns.readlines()\n",
    "    \n",
    "    mace.close()\n",
    "    mns.close()\n",
    "    \n",
    "    mace_dct = []\n",
    "    mns_dct = []\n",
    "    \n",
    "    for i in range(9,len(mace_contents)):\n",
    "        #key_mace = int(mace_contents[i].split()[0])\n",
    "        #key_mns = int(mns_contents[i].split()[0])\n",
    "        #monthly_mace = []\n",
    "        #monthly_mns = []\n",
    "        for j in range(1,13):\n",
    "            mace_dct.append(float(mace_contents[i].split()[j]))\n",
    "            mns_dct.append(float(mns_contents[i].split()[j]))\n",
    "        #mace_dct[key_mace] = monthly_mace\n",
    "        #mns_dct[key_mns] = monthly_mns\n",
    "    \n",
    "    return np.array(mace_dct), np.array(mns_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e212c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mace,mns = open_monthly_data()\n",
    "factual,cfl,ace = open_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6855d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual = factual.to_array().transpose(\"time\",\"variable\",\"lat\",\"lon\")\n",
    "factual = factual.stack(information=['lat','lon','variable'])\n",
    "factual = factual.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ab0024",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(factual,mace,test_size=0.25,shuffle=True, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "        \"metric\": 'rmse',\n",
    "        \"estimator_list\": 'auto',\n",
    "        \"task\": 'regression',\n",
    "        \"time_budget\": 300,\n",
    "        \"log_file_name\": \"./automl_factual.log\"\n",
    "    }\n",
    "automl.fit(X_train=X_train, y_train=y_train,**automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efa538",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_idxs_y = [i for i, x in enumerate(y_test) if x == 0]\n",
    "y_test_nz = []\n",
    "X_test_nz = []\n",
    "for i in range(len(y_test)):\n",
    "    if(i in zero_idxs_y):\n",
    "        continue\n",
    "    y_test_nz.append(y_test[i])\n",
    "    X_test_nz.append(X_test[i])\n",
    "y_test_nz = np.array(y_test_nz)\n",
    "X_test_nz = np.array(X_test_nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d97b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nz = automl.predict(X_test_nz)\n",
    "eval_results(y_test_nz,y_pred_nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "eval_results(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d281642",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(automl.model.estimator.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_l = []\n",
    "ice_l = []\n",
    "p_l = []\n",
    "ua_l = []\n",
    "va_l = []\n",
    "for i in range(0,len(automl.model.estimator.feature_importances_),5):\n",
    "    ua_l.append(automl.model.estimator.feature_importances_[i])\n",
    "    va_l.append(automl.model.estimator.feature_importances_[i+1])\n",
    "    p_l.append(automl.model.estimator.feature_importances_[i+2])\n",
    "    ice_l.append(automl.model.estimator.feature_importances_[i+3])\n",
    "    sst_l.append(automl.model.estimator.feature_importances_[i+4])\n",
    "total = sum(sst_l) + sum(ice_l) + sum(p_l) + sum(ua_l) + sum(va_l)\n",
    "print('SST FI: ' + str(sum(sst_l)/total*100) + \"%\")\n",
    "print('Ice FI: ' + str(sum(ice_l)/total*100) + \"%\")\n",
    "print('Pressure FI: ' + str(sum(p_l)/total*100) + \"%\")\n",
    "print('Ua FI: ' + str(sum(ua_l)/total*100) + \"%\")\n",
    "print('Va FI: ' + str(sum(va_l)/total*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a1195",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [i for i, x in enumerate(my_list) if x == \"whatever\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mace,mns = open_monthly_data()\n",
    "factual_1,cfl,ace = open_data()\n",
    "factual_2,cfl,ace = open_data()\n",
    "factual_3,cfl,ace = open_data()\n",
    "factual_1 = factual_1.drop(\"msl\")\n",
    "factual_2 = factual_2.drop(\"u10\")\n",
    "factual_2 = factual_2.drop(\"v10\")\n",
    "factual_3 = factual_3.drop(\"siconc\")\n",
    "factual_3 = factual_3.drop(\"sst\")\n",
    "factual_1 = factual_1.to_array().transpose(\"time\",\"variable\",\"lat\",\"lon\")\n",
    "factual_1 = factual_1.stack(information=['lat','lon','variable'])\n",
    "factual_1 = factual_1.to_numpy()\n",
    "factual_2 = factual_2.to_array().transpose(\"time\",\"variable\",\"lat\",\"lon\")\n",
    "factual_2 = factual_2.stack(information=['lat','lon','variable'])\n",
    "factual_2 = factual_2.to_numpy()\n",
    "factual_3 = factual_3.to_array().transpose(\"time\",\"variable\",\"lat\",\"lon\")\n",
    "factual_3 = factual_3.stack(information=['lat','lon','variable'])\n",
    "factual_3 = factual_3.to_numpy()\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(factual_1,mace,test_size=0.25,shuffle=True, random_state=66)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(factual_2,mace,test_size=0.25,shuffle=True, random_state=66)\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(factual_3,mace,test_size=0.25,shuffle=True, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953449ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(factual_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_1 = AutoML()\n",
    "automl_settings = {\n",
    "        \"metric\": 'rmse',\n",
    "        \"estimator_list\": 'auto',\n",
    "        \"task\": 'regression',\n",
    "        \"time_budget\": 300,\n",
    "        \"log_file_name\": \"./automl_factual.log\"\n",
    "    }\n",
    "automl_1.fit(X_train=X_train_1, y_train=y_train_1,**automl_settings)\n",
    "automl_2 = AutoML()\n",
    "automl_settings = {\n",
    "        \"metric\": 'rmse',\n",
    "        \"estimator_list\": 'auto',\n",
    "        \"task\": 'regression',\n",
    "        \"time_budget\": 300,\n",
    "        \"log_file_name\": \"./automl_factual.log\"\n",
    "    }\n",
    "automl_2.fit(X_train=X_train_2, y_train=y_train_2,**automl_settings)\n",
    "automl_3 = AutoML()\n",
    "automl_settings = {\n",
    "        \"metric\": 'rmse',\n",
    "        \"estimator_list\": 'auto',\n",
    "        \"task\": 'regression',\n",
    "        \"time_budget\": 300,\n",
    "        \"log_file_name\": \"./automl_factual.log\"\n",
    "    }\n",
    "automl_3.fit(X_train=X_train_3, y_train=y_train_3,**automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4207ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = automl_1.predict(X_test_1)\n",
    "eval_results(y_test_1,y_pred_1)\n",
    "y_pred_2 = automl_2.predict(X_test_2)\n",
    "eval_results(y_test_2,y_pred_2)\n",
    "y_pred_3 = automl_3.predict(X_test_3)\n",
    "eval_results(y_test_3,y_pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a754d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mace,mns = open_monthly_data()\n",
    "factual,cfl,ace, land_mask = water_open_data()\n",
    "factual = factual.to_array().transpose(\"time\",\"lat\",\"lon\",\"variable\")\n",
    "land_mask = land_mask.to_array()\n",
    "land_mask = np.dstack([land_mask]*5)\n",
    "land_mask = np.dstack([land_mask]*732)\n",
    "land_mask = land_mask.reshape((732,64,41,5))\n",
    "land_mask = np.where(land_mask < 0.5, np.NaN, 1)\n",
    "factual = np.multiply(factual,land_mask)\n",
    "\n",
    "factual = factual.stack(information=['lat','lon','variable'])\n",
    "factual = factual.to_numpy()\n",
    "factual = factual[:, ~np.isnan(factual).any(axis=0)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(factual,mace,test_size=0.3,shuffle=True, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82aad50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33402dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "        \"metric\": 'rmse',\n",
    "        \"estimator_list\": 'auto',\n",
    "        \"task\": 'regression',\n",
    "        \"time_budget\": 300,\n",
    "        \"log_file_name\": \"./automl_factual.log\"\n",
    "    }\n",
    "automl.fit(X_train=X_train, y_train=y_train,**automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "eval_results(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eed2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mace,mns = open_monthly_data()\n",
    "factual,cfl,ace = open_data()\n",
    "factual = factual.to_array().transpose(\"time\",\"variable\",\"lat\",\"lon\")\n",
    "factual = factual.stack(information=['lat','lon','variable'])\n",
    "factual = factual.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mace = []\n",
    "new_factual = []\n",
    "for i in range(732):\n",
    "    if(i % 12 >= 4 and i % 12 <= 10):\n",
    "        new_mace.append(mace[i])\n",
    "        new_factual.append(factual[i])\n",
    "        \n",
    "new_mace = np.array(new_mace)\n",
    "new_factual = np.array(new_factual)\n",
    "print(np.shape(mace))\n",
    "print(np.shape(factual))\n",
    "print(np.shape(new_mace))\n",
    "print(np.shape(new_factual))\n",
    "print(mac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_factual,new_mace,test_size=0.3,shuffle=True, random_state=66)\n",
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "        \"metric\": 'rmse',\n",
    "        \"estimator_list\": 'auto',\n",
    "        \"task\": 'regression',\n",
    "        \"time_budget\": 300,\n",
    "        \"log_file_name\": \"./automl_factual.log\"\n",
    "    }\n",
    "automl.fit(X_train=X_train, y_train=y_train,**automl_settings)\n",
    "y_pred = automl.predict(X_test)\n",
    "eval_results(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "eval_results(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb12ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unregrid_open_data():\n",
    "    #Open the datasets\n",
    "    factual = xr.open_mfdataset(\"factual/*.nc\")\n",
    "    cfl = xr.open_mfdataset(\"eth_cfl/*.nc\", join='inner', compat='override')\n",
    "    \n",
    "    factual = factual.reduce(np.nansum, dim='expver',keep_attrs=True)\n",
    "    cfl[\"lon\"] = np.arange(-180,180,2.5)\n",
    "    factual = factual.rename({\"latitude\":\"lat\",\"longitude\":\"lon\"})\n",
    "    cfl = cfl.sel(lat=slice(-60,60),lon=slice(-80,20))\n",
    "    \n",
    "    factual = factual.isel(time=slice(0,732)) # if monthly data\n",
    "    \n",
    "    pred_df = pd.read_csv(\"yearly_activity.csv\")\n",
    "    pred_df = pred_df.loc[pred_df['Year'] >= 1950]\n",
    "    ace_raw = pred_df['Accumulated Cyclone Energy']\n",
    "    ace = np.array(ace_raw)\n",
    "    \n",
    "    return factual,cfl,ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mace,mns = open_monthly_data()\n",
    "factual,cfl,ace = open_data()\n",
    "factual = factual.to_array().transpose(\"time\",\"variable\",\"lat\",\"lon\")\n",
    "factual = factual.stack(information=['lat','lon','variable'])\n",
    "factual = factual.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c32a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(factual, mns,test_size=0.3,shuffle=True, random_state=66)\n",
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "        \"metric\": 'rmse',\n",
    "        \"estimator_list\": 'auto',\n",
    "        \"task\": 'regression',\n",
    "        \"time_budget\": 300,\n",
    "        \"log_file_name\": \"./automl_factual.log\"\n",
    "    }\n",
    "automl.fit(X_train=X_train, y_train=y_train,**automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663accdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "eval_results(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068cbb6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfl = xr.open_mfdataset(\"init_ctf_pred.nc\")\n",
    "print(cfl.dims)\n",
    "cfl = cfl.to_array().transpose(\"time\",\"variable\",\"lat\",\"lon\")\n",
    "cfl = cfl.stack(information=['lat','lon','variable'])\n",
    "cfl.dropna('lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9fe4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ctf_data():\n",
    "    #Open the datasets\n",
    "    \n",
    "    cfl = xr.open_mfdataset(\"eth_cfl/*.nc\", join='inner', compat='override')\n",
    "    \n",
    "    cfl[\"lon\"] = np.arange(-180,180,2.5)\n",
    "    cfl = cfl.sel(lat=slice(-60,60),lon=slice(-80,20))\n",
    "\n",
    "    \n",
    "    return cfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e098ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfl = open_ctf_data()\n",
    "cfl = cfl.drop(\"time_bnds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a78f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfl['ua'] = cfl['ua'].sel(plev=20000)\n",
    "cfl['va'] = cfl['va'].sel(plev=20000)\n",
    "var_list = ['SST_cpl','ice_cov','psl', 'ua', 'va']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f73667",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfl = cfl.drop('plev')\n",
    "ret = cfl.sel(time=cfl['time'][108:])[var_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f85646",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = ret.to_array().transpose(\"time\",\"variable\",\"lat\",\"lon\")\n",
    "ret = ret.stack(information=['lat','lon','variable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5dea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_results = automl.predict(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46736195",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(counterfactual_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a5abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctf_2020 = np.random.rand(12,13120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1638322",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(automl.predict(ctf_2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b910986",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctf_2020 = np.loadtxt('ctf_ensemble_0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3fcac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(ctf_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.predict(ctf_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db322b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
